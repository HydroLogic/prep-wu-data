1. Tokenize Tweets

  # ~/ics/wuclan/examples/twitter/parse/extract_tweet_tokens.rb --rm --reduce_command=`which cat` --reduce_tasks=23 --run ripd/com.tw/sampled/parsed/com.twitter3/tweet.tsv  tmp/sampled_toks
  
  ~/ics/wuclan/examples/twitter/parse/extract_tweet_tokens.rb --rm --reduce_command=`which cat` --reduce_tasks=23 --run /user/flip/fixd/tw/out/tweet        fixd/tw/tokens/all
  ~/ics/wuclan/examples/twitter/parse/extract_tweet_tokens.rb --rm --reduce_command=`which cat` --reduce_tasks=23 --run /user/flip/fixd/tw/out/search_tweet fixd/tw/tokens/from_search_tweet

2. (optionally) Stratify

    ~/ics/wukong/bin/hdp-stream2           \
      --rm --reduce_tasks=23               \
      --map_command="`which egrep` \"^(smiley|tweet_url|hashtag)\"" \
      --reduce_command=`which cat`         \
      --partition_fields=1 --sort_fields=3 \
      --ignore_exit_status                 \
      fixd/tw/tokens/all                   \
      fixd/tw/tokens/toks

3. Rollup tweets by hour
   To edit:
   * input path
   * output path
   * PARALLEL in the group statement

4. Ditch to disk

