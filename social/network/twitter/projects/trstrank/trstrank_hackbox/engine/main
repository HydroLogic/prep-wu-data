#!/usr/bin/env jruby

require 'rubygems'
require 'swineherd' ; include Swineherd
require 'swineherd/script/pig_script' ; include Swineherd::Script
require 'swineherd/script/wukong_script'
require 'json'

inputdir  = ARGV[0]
outputdir = ARGV[1]


#
# Get new hadoop file system
#
hdfs = Swineherd::FileSystem.get(:hdfs)

#
# Read in working config file
#
options = YAML.load(hdfs.open(File.join(outputdir, "env", "working_environment.yaml")).read)

flow = Workflow.new(options['flow_id']) do

  #
  # Scripts needed to run trstrank workflow
  #
  templates = File.dirname(__FILE__)+'/templates'
  graph_assembler      = PigScript.new(File.join(templates, 'assemble_multigraph.pig.erb'))
  degrees_calculator   = PigScript.new(File.join(templates, 'degree_distribution.pig.erb'))
  pagerank_initializer = PigScript.new(File.join(templates, 'pagerank_initialize.pig.erb'))
  pagerank_iterator    = PigScript.new(File.join(templates, 'pagerank_iterate.pig.erb'))
  followers_joiner     = PigScript.new(File.join(templates, 'join_and_scale.pig.erb'))
  followers_binner     = WukongScript.new(File.join(templates, 'trst_quotient.rb'))
  trstrank_assembler   = PigScript.new(File.join(templates, 'trstrank_assembler.pig.erb'))

  #
  # Take a_follows_b and a_atsigns_b and assemble multigraph
  #
  task :assemble_multigraph do
    graph_assembler.env['PIG_OPTS'] = options['pig_options']
    graph_assembler.attributes = {
      :hdfs              => "hdfs://#{options['hdfs']}",
      :jars              => options['hbase_jars'],
      :twitter_rel_table => options['twitter_rel_table'],
      :reduce_tasks      => options['hadoop_reduce_tasks'],
      :out               => next_output(:assemble_multigraph)
    }
    graph_assembler.run unless hdfs.exists? latest_output(:assemble_multigraph)
  end

  #
  # Use the multigraph to create initial input for pagerank
  #
  task :pagerank_initialize => [:assemble_multigraph] do
    pagerank_initializer.env['PIG_OPTS'] = options['pig_options']
    pagerank_initializer.attributes = {
      :hdfs         => "hdfs://#{options['hdfs']}",
      :multigraph   => latest_output(:assemble_multigraph),
      :reduce_tasks => options['hadoop_reduce_tasks'],
      :out          => next_output(:pagerank_initialize)
    }
    pagerank_initializer.run unless hdfs.exists? latest_output(:pagerank_initialize)
  end
  
  
  #
  # Iterate pagerank multiple times over the multigraph
  #
  task :pagerank_iterate => [:pagerank_initialize] do
    pagerank_iterator.env['PIG_OPTS'] = options['pig_options']
    pagerank_iterator.attributes = {
      :hdfs              => "hdfs://#{options['hdfs']}",
      :reduce_tasks      => options['hadoop_reduce_tasks'],
      :pagerank_damping  => options['pagerank_damping'],
      :current_iteration => latest_output(:pagerank_initialize)
    }
    options['pagerank_iterations'].to_i.times do
      pagerank_iterator.attributes[:next_iteration]     = next_output(:pagerank_iterate)
      pagerank_iterator.run unless hdfs.exists? latest_output(:pagerank_iterate)
      pagerank_iterator.refresh!
      pagerank_iterator.attributes[:currrent_iteration] = latest_output(:pagerank_iterate)
    end
  end
  
  
  #
  # Calculate the degree distribution of the multigraph
  #
  task :multigraph_degrees => [:assemble_multigraph] do
    degrees_calculator.env['PIG_OPTIONS'] = options['pig_options']
    degrees_calculator.attributes = {
      :hdfs                => "hdfs://#{options['hdfs']}",
      :reduce_tasks        => options['hadoop_reduce_tasks'],
      :multigraph          => latest_output(:assemble_multigraph),
      :degree_distribution => next_output(:multigraph_degrees)
    }
    degrees_calculator.run unless hdfs.exists? latest_output(:multigraph_degrees)
  end

  #
  #
  #
  
  #
  # FIXME!!!! we need an s3 filesystem interface
  #
  def hackety_exists? target
    system %Q{hadoop fs -test -e #{target}}
  end
  
  task :store_valuable_graph_data => [:multigraph_degrees] do
    deg_dist_out   = File.join(options['s3_graph_dir'], options['flow_id'].to_s, 'degree_distribution')
    multigraph_out = File.join(options['s3_graph_dir'], options['flow_id'].to_s, 'multigraph')
    hdfs.stream(latest_output(:multigraph_degrees), deg_dist_out) unless hackety_exists? deg_dist_out
    hdfs.stream(latest_output(:assemble_multigraph), multigraph_out) unless hackety_exists? multigraph_out
  end
  #
  #
  #
  
  #
  # Scales final pagerank values to (0-10) and joins it with the followers
  # observed.
  #
  # FIXME: why doesn't multitask work here?
  #
  # multitask :join_pagerank_with_followers => [:multigraph_degrees, :pagerank_iterate] do
  task :join_pagerank_with_followers => [:store_valuable_graph_data, :pagerank_iterate] do
<<<<<<< HEAD
    followers_joiner.env['PIG_OPTIONS'] = options['pig_options']
=======
    followers_joiner.env['PIG_OPTS'] = options['pig_options']
>>>>>>> b5718597ab923206d3b7bd77e4dfbc3eaf65a1d7
    followers_joiner.attributes = {
      :hdfs                => "hdfs://#{options['hdfs']}",
      :reduce_tasks        => options['hadoop_reduce_tasks'],      
      :pig_home            => options['pig_home'],
      :degree_distribution => latest_output(:multigraph_degrees),
      :pagerank_output     => latest_output(:pagerank_iterate),
      :out                 => next_output(:join_pagerank_with_followers)
    }
    followers_joiner.run unless hdfs.exists? latest_output(:join_pagerank_with_followers)
  end
  
  
  #
  # Bin users by followers observed and get percentiles
  #
  task :trstquotient => [:join_pagerank_with_followers] do
    followers_binner.output << next_output(:trstquotient)
    followers_binner.input  << latest_output(:join_pagerank_with_followers)
    followers_binner.options = {
      :forank_table => File.join(templates, 'forank_table.rb'),
      :atrank_table => File.join(templates, 'atrank_table.rb')
    }
    followers_binner.run unless hdfs.exists? latest_output(:trstquotient)
  end
  
  
  #
  # Assemble all the components to form final trstrank table
  #
  task :assemble_trstrank => [:trstquotient] do
    trstrank_assembler.env['PIG_OPTIONS'] = options['pig_options']
    trstrank_assembler.env['PIG_CLASSPATH'] = options['pig_classpath']
    trstrank_assembler.attributes = {
      :jars           => options['hbase_jars'],
      :twuid_table    => options['twitter_users_table'],
      :reduce_tasks   => options['hadoop_reduce_tasks'],
      :twuid_cf       => options['twitter_users_cf'],
      :rank_with_tq   => latest_output(:trstquotient),
      :s3_out         => File.join(options['s3_graph_dir'], "#{options['flow_id']}", 'trstrank_table'),
      :trstrank_table => options['trstrank_table'],
      :trstrank_cf    => 'base'
    }
    mock_output = next_output(:assemble_trstrank)
    trstrank_assembler.run unless hdfs.exists? latest_output(:assemble_trstrank)

    hdfs.mkpath latest_output(:assemble_trstrank) # hack so it wont run again
  end
  
end

flow.workdir = File.join(inputdir, "rawd")
flow.describe
flow.run(:assemble_trstrank)
