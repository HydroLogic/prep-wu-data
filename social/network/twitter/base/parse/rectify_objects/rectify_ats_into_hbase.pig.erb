<% jars.each do |jar| %>
register <%= jar %>;
<% end %>
        
data         = LOAD '<%= twuid_table %>' USING com.infochimps.hadoop.pig.hbase.StaticFamilyStorage('info:screen_name', '-loadKey -config <%= hbase_config %>') AS (user_id:int, screen_name:chararray);
a_atsigns_bn = LOAD '<%= ats %>' AS (rsrc:chararray, user_a_id:long, user_b_id:long, rel_type:chararray, twid:long, crat:long, user_b_sn:chararray, rel_tw_id:long);

filtered     = FILTER a_atsigns_bn BY user_b_sn IS NOT NULL;
ats_joined   = JOIN data BY screen_name, filtered BY user_b_sn PARALLEL <%= reduce_tasks %>;
ats_filtered = FILTER ats_joined BY data::user_id IS NOT NULL; -- naughty naughty
a_atsigns_b  = FOREACH ats_filtered GENERATE
                    filtered::user_a_id AS user_a_id,
                    data::user_id       AS user_b_id,
                    filtered::rel_type  AS rel_type,
                    filtered::twid      AS tweet_id,
                    filtered::crat      AS created_at,
                    filtered::user_b_sn AS user_b_sn,
                    filtered::rel_tw_id AS rel_tw_id
               ;

generated = FOREACH a_atsigns_b {
              row_key   = CONCAT(CONCAT((chararray)user_a_id, ':'), (chararray)user_b_id);
              col_fam   = (rel_type == 're' ? 'reply' : (rel_type == 'me' ? 'mention' : (rel_type == 'rt' ? 'retweet' : 'unknown')));
              json_meta = com.infochimps.hadoop.pig.TupleToJson(created_at, user_b_sn, rel_tw_id);
              GENERATE
                row_key   AS row_key,
                col_fam   AS col_fam,
                tweet_id  AS col_name,
                json_meta AS col_val
              ;
            };
to_hbase = FILTER generated BY (col_fam != 'unknown');
STORE to_hbase INTO '<%= ats_table %>' USING com.infochimps.hadoop.pig.hbase.DynamicFamilyStorage('<%= hbase_config %>');
