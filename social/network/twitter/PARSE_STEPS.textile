

./extract_twitter_user_ids_from_twitter_user_anythings.rb --rm --run \
  /data/rawd/social/network/twitter/objects/twitter_user\*,/data/rawd/social/network/twitter/objects/a_follows_b,/data/rawd/social/network/twitter/objects/tweet \
  /data/rawd/social/network/twitter/scrape_stats/twitter_user_ids &
hdp-catd /data/rawd/social/network/twitter/scrape_stats/twitter_user_ids > /data/rawd/social/network/twitter/scrape_stats/twitter_user_ids.tsv &



    * /data/rawd/social/network/twitter/objects has uniqd data that includes everything (october parse merged with now).  It's possible that some duplicate fields records exist if their id's were zero-padded in one place and not another. Still need to extract a_favorites_b and twitter_search_id records.
    * parse_and_scrape_helpers/requests_stats/raw_requests_metadata.rb -- the type, request info, page, date, and response code for each request. Data in    /data/rawd/social/network/twitter/scrape_stats/requests_metadata/raw_requests_metadata
    * extract_twitter_user_ids_from_twitter_user_anythings.rb -- look for every api user_id that's ever been seen and merge it into one big list (for feeding back into scrapers later).  Was run over everything but the a_follows_b models. Data in /data/rawd/social/network/twitter/scrape_stats/twitter_user_ids on the HDFS and in /data/rawd/social/network/twitter/scrape_stats/twitter_user_ids.tsv on gibbon master.
    * raw, un-uniqd data is in /data/rawd/social/network/twitter/parsed/\*/\*

